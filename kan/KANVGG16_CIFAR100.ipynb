{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSQpS0W8jMoN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KANLinear class definition as provided\n",
        "class KANLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, grid_size=5, spline_order=3, scale_noise=0.1, scale_base=1.0, scale_spline=1.0, enable_standalone_scale_spline=True, base_activation=nn.SiLU, grid_eps=0.02, grid_range=[-1, 1]):\n",
        "        super(KANLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
        "        grid = ((torch.arange(-spline_order, grid_size + spline_order + 1) * h + grid_range[0]).expand(in_features, -1).contiguous())\n",
        "        self.register_buffer(\"grid\", grid)\n",
        "\n",
        "        self.base_weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.spline_weight = nn.Parameter(torch.Tensor(out_features, in_features, grid_size + spline_order))\n",
        "        if enable_standalone_scale_spline:\n",
        "            self.spline_scaler = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "\n",
        "        self.scale_noise = scale_noise\n",
        "        self.scale_base = scale_base\n",
        "        self.scale_spline = scale_spline\n",
        "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
        "        self.base_activation = base_activation()\n",
        "        self.grid_eps = grid_eps\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
        "        with torch.no_grad():\n",
        "            noise = ((torch.rand(self.grid_size + 1, self.in_features, self.out_features) - 1 / 2) * self.scale_noise / self.grid_size)\n",
        "            self.spline_weight.data.copy_((self.scale_spline if not self.enable_standalone_scale_spline else 1.0) * self.curve2coeff(self.grid.T[self.spline_order : -self.spline_order], noise))\n",
        "            if self.enable_standalone_scale_spline:\n",
        "                nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
        "\n",
        "    def b_splines(self, x: torch.Tensor):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        grid = self.grid\n",
        "        x = x.unsqueeze(-1)\n",
        "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            bases = ((x - grid[:, : -(k + 1)]) / (grid[:, k:-1] - grid[:, : -(k + 1)]) * bases[:, :, :-1]) + ((grid[:, k + 1 :] - x) / (grid[:, k + 1 :] - grid[:, 1:(-k)]) * bases[:, :, 1:])\n",
        "        assert bases.size() == (x.size(0), self.in_features, self.grid_size + self.spline_order)\n",
        "        return bases.contiguous()\n",
        "\n",
        "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
        "        A = self.b_splines(x).transpose(0, 1)\n",
        "        B = y.transpose(0, 1)\n",
        "        solution = torch.linalg.lstsq(A, B).solution\n",
        "        result = solution.permute(2, 0, 1)\n",
        "        assert result.size() == (self.out_features, self.in_features, self.grid_size + self.spline_order)\n",
        "        return result.contiguous()\n",
        "\n",
        "    @property\n",
        "    def scaled_spline_weight(self):\n",
        "        return self.spline_weight * (self.spline_scaler.unsqueeze(-1) if self.enable_standalone_scale_spline else 1.0)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
        "        spline_output = F.linear(self.b_splines(x).view(x.size(0), -1), self.scaled_spline_weight.view(self.out_features, -1))\n",
        "        return base_output + spline_output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        batch = x.size(0)\n",
        "        splines = self.b_splines(x).permute(1, 0, 2)\n",
        "        orig_coeff = self.scaled_spline_weight.permute(1, 2, 0)\n",
        "        unreduced_spline_output = torch.bmm(splines, orig_coeff).permute(1, 0, 2)\n",
        "        x_sorted = torch.sort(x, dim=0)[0]\n",
        "        grid_adaptive = x_sorted[torch.linspace(0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device)]\n",
        "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
        "        grid_uniform = (torch.arange(self.grid_size + 1, dtype=torch.float32, device=x.device).unsqueeze(1) * uniform_step + x_sorted[0] - margin)\n",
        "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
        "        grid = torch.cat([grid[:1] - uniform_step * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1), grid, grid[-1:] + uniform_step * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1)], dim=0)\n",
        "        self.grid.copy_(grid.T)\n",
        "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        l1_fake = self.spline_weight.abs().mean(-1)\n",
        "        regularization_loss_activation = l1_fake.sum()\n",
        "        p = l1_fake / regularization_loss_activation\n",
        "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
        "        return regularize_activation * regularization_loss_activation + regularize_entropy * regularization_loss_entropy\n",
        "\n"
      ],
      "metadata": {
        "id": "oKAls8iErpvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KANVGG16(nn.Module):\n",
        "    def __init__(self, num_classes=100):  # CIFAR100 has 100 classes\n",
        "        super(KANVGG16, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Convolutional block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Convolutional block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Convolutional block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Convolutional block 4\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # Convolutional block 5\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            KANLinear(512 * 1 * 1, 4096),  # Adjusted for CIFAR100 image size\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            KANLinear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            KANLinear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HLtvWZ3csBFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for the training and testing data\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR100 dataset\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n",
        "\n",
        "# Function to visualize images\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\"\"\"\n",
        "# Visualize 5 images from each class\n",
        "def visualize_images():\n",
        "    classes = trainset.classes\n",
        "    class_indices = {i: [] for i in range(len(classes))}\n",
        "    for idx, (_, label) in enumerate(trainset):\n",
        "        if len(class_indices[label]) < 5:\n",
        "            class_indices[label].append(idx)\n",
        "        if all(len(indices) >= 5 for indices in class_indices.values()):\n",
        "            break\n",
        "\n",
        "    fig, axes = plt.subplots(len(classes), 5, figsize=(15, 30))\n",
        "    for cls, indices in class_indices.items():\n",
        "        for i, idx in enumerate(indices):\n",
        "            img, _ = trainset[idx]\n",
        "            img = img / 2 + 0.5  # Unnormalize\n",
        "            npimg = img.numpy()\n",
        "            axes[cls, i].imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "            axes[cls, i].set_title(classes[cls])\n",
        "            axes[cls, i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "visualize_images()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nPUsW06qrv48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model, define the loss function and the optimizer\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = KANVGG16(num_classes=100).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Early stopping parameters\n",
        "patience = 5\n",
        "best_loss = float('inf')\n",
        "trigger_times = 0\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Split train set into train and validation sets\n",
        "train_indices, val_indices = train_test_split(list(range(len(trainset))), test_size=0.2, stratify=trainset.targets)\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, sampler=train_sampler, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(trainset, batch_size=64, sampler=val_sampler, num_workers=2)\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(50):  # Maximum epochs\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    train_losses.append(running_loss / len(trainloader))\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_losses.append(val_loss / len(valloader))\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Training Loss: {train_losses[-1]:.3f}, Validation Loss: {val_losses[-1]:.3f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    # Check early stopping condition\n",
        "    if val_losses[-1] < best_loss:\n",
        "        best_loss = val_losses[-1]\n",
        "        trigger_times = 0\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "    else:\n",
        "        trigger_times += 1\n",
        "        if trigger_times >= patience:\n",
        "            print('Early stopping!')\n",
        "            break\n",
        "\n",
        "print(\"Finished Training\")\n",
        "\n",
        "# Plot training and validation loss\n",
        "def plot_loss(train_losses, val_losses):\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Plot validation accuracy\n",
        "def plot_accuracy(val_accuracies):\n",
        "    plt.figure()\n",
        "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the losses and accuracy\n",
        "plot_loss(train_losses, val_losses)\n",
        "plot_accuracy(val_accuracies)\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "QoiuUsG1s6iM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}